{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SII3H4AUQ-UG",
        "outputId": "851aaedb-52a2-4425-ab2f-4dedc184eec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/ML/Llama2\"\n",
        "# !git clone https://github.com/tloen/alpaca-lora.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fDscoMuRMtU",
        "outputId": "52a62267-b448-4736-ac94-71d0fe03be76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/Llama2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### エラー対策\n",
        "/alpaca-lora/finetune.pyの264-271の\n",
        "```python\n",
        "model.state_dict = (\n",
        "    lambda self, *_, **__: get_peft_model_state_dict(\n",
        "        self, old_state_dict()\n",
        "    )\n",
        ").__get__(model, type(model))\n",
        "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
        "    model = torch.compile(model)\n",
        "```\n",
        "の部分をコメントアウトする。"
      ],
      "metadata": {
        "id": "hJ_DsAKez1gy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd alpaca-lora/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asWWqs8hRf0p",
        "outputId": "8a2d1201-1dbe-4613-c9d4-f92558cbc8fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/Llama2/alpaca-lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHOijvuoTNVV",
        "outputId": "29ac97d4-f794-41ca-d8e7-2e0c7c1fe310"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_1k.json               export_hf_checkpoint.py          pyproject.toml\n",
            "alpaca_data_cleaned_archive.json  export_state_dict_checkpoint.py  README.md\n",
            "alpaca_data_gpt4.json             finetune.py                      requirements.txt\n",
            "alpaca_data.json                  generate.py                      \u001b[0m\u001b[01;34mtemplates\u001b[0m/\n",
            "DATA_LICENSE                      lengths.ipynb                    \u001b[01;34mutils\u001b[0m/\n",
            "docker-compose.yml                LICENSE\n",
            "Dockerfile                        \u001b[01;34mlora-alpaca-1k\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCBkWpN2TrUh",
        "outputId": "7ff2ccd4-8042-4bee-ade2-0c62b862cdc6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/peft.git (from -r requirements.txt (line 9))\n",
            "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-pgel3lbk\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-pgel3lbk\n",
            "  Resolved https://github.com/huggingface/peft.git to commit 7e84dec20b3106bdd0a90ba8e80187f0aec835b7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.27.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.42.0)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (24.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.18.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: transformers>=4.28.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.38.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.1.99)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.50.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->-r requirements.txt (line 4)) (1.11.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (4.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (7.34.0)\n",
            "Requirement already satisfied: tokenize-rt>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from black->-r requirements.txt (line 5)) (5.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 7)) (3.9.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 8)) (2.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.0->-r requirements.txt (line 10)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.28.0->-r requirements.txt (line 10)) (0.15.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.6.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.27.0)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (3.7.1)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (3.9.15)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (2.6.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.0.9)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (0.27.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 12)) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 7)) (4.0.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.8.0->black->-r requirements.txt (line 5)) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 7)) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio->-r requirements.txt (line 12)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio->-r requirements.txt (line 12)) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 7)) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 12)) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 12)) (0.36.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 12)) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 12)) (1.0.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 12)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.8.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 12)) (0.18.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio->-r requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r requirements.txt (line 1)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head alpaca_data.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue-mkKAkUERl",
        "outputId": "c9364373-c35a-45e0-9c4a-df74ad99712b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"instruction\": \"Give three tips for staying healthy.\",\n",
            "        \"input\": \"\",\n",
            "        \"output\": \"1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.\"\n",
            "    },\n",
            "    {\n",
            "        \"instruction\": \"What are the three primary colors?\",\n",
            "        \"input\": \"\",\n",
            "        \"output\": \"The three primary colors are red, blue, and yellow.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json(\"alpaca_data.json\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j6gYgdowUSGt",
        "outputId": "a9946e63-43df-40e4-dafa-a0e4a81165ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             instruction  \\\n",
              "0                   Give three tips for staying healthy.   \n",
              "1                     What are the three primary colors?   \n",
              "2                     Describe the structure of an atom.   \n",
              "3                       How can we reduce air pollution?   \n",
              "4      Describe a time when you had to make a difficu...   \n",
              "...                                                  ...   \n",
              "51997  Generate an example of what a resume should li...   \n",
              "51998  Arrange the items given below in the order to ...   \n",
              "51999  Write an introductory paragraph about a famous...   \n",
              "52000  Generate a list of five things one should keep...   \n",
              "52001  Analyze the given legal document and explain t...   \n",
              "\n",
              "                                                   input  \\\n",
              "0                                                          \n",
              "1                                                          \n",
              "2                                                          \n",
              "3                                                          \n",
              "4                                                          \n",
              "...                                                  ...   \n",
              "51997                                                      \n",
              "51998                                   cake, me, eating   \n",
              "51999                                     Michelle Obama   \n",
              "52000                                                      \n",
              "52001  The following is an excerpt from a contract be...   \n",
              "\n",
              "                                                  output  \n",
              "0      1.Eat a balanced diet and make sure to include...  \n",
              "1      The three primary colors are red, blue, and ye...  \n",
              "2      An atom is made up of a nucleus, which contain...  \n",
              "3      There are a number of ways to reduce air pollu...  \n",
              "4      I had to make a difficult decision when I was ...  \n",
              "...                                                  ...  \n",
              "51997  Jean Tremaine\\n1234 Main Street, Anytown, CA 9...  \n",
              "51998                                     I eating cake.  \n",
              "51999  Michelle Obama is an inspirational woman who r...  \n",
              "52000  1. Research potential opportunities and carefu...  \n",
              "52001  This legal document states that Company A has ...  \n",
              "\n",
              "[52002 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96fc95cb-2221-4ec9-852f-2ce8687cd1e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>instruction</th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Give three tips for staying healthy.</td>\n",
              "      <td></td>\n",
              "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the three primary colors?</td>\n",
              "      <td></td>\n",
              "      <td>The three primary colors are red, blue, and ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Describe the structure of an atom.</td>\n",
              "      <td></td>\n",
              "      <td>An atom is made up of a nucleus, which contain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can we reduce air pollution?</td>\n",
              "      <td></td>\n",
              "      <td>There are a number of ways to reduce air pollu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Describe a time when you had to make a difficu...</td>\n",
              "      <td></td>\n",
              "      <td>I had to make a difficult decision when I was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51997</th>\n",
              "      <td>Generate an example of what a resume should li...</td>\n",
              "      <td></td>\n",
              "      <td>Jean Tremaine\\n1234 Main Street, Anytown, CA 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51998</th>\n",
              "      <td>Arrange the items given below in the order to ...</td>\n",
              "      <td>cake, me, eating</td>\n",
              "      <td>I eating cake.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51999</th>\n",
              "      <td>Write an introductory paragraph about a famous...</td>\n",
              "      <td>Michelle Obama</td>\n",
              "      <td>Michelle Obama is an inspirational woman who r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52000</th>\n",
              "      <td>Generate a list of five things one should keep...</td>\n",
              "      <td></td>\n",
              "      <td>1. Research potential opportunities and carefu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52001</th>\n",
              "      <td>Analyze the given legal document and explain t...</td>\n",
              "      <td>The following is an excerpt from a contract be...</td>\n",
              "      <td>This legal document states that Company A has ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52002 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96fc95cb-2221-4ec9-852f-2ce8687cd1e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-96fc95cb-2221-4ec9-852f-2ce8687cd1e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-96fc95cb-2221-4ec9-852f-2ce8687cd1e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8da1f141-d362-4a44-b373-bfda0ac5503b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8da1f141-d362-4a44-b373-bfda0ac5503b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8da1f141-d362-4a44-b373-bfda0ac5503b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6de80f40-29b3-4e37-b512-a8d8bc7b661f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6de80f40-29b3-4e37-b512-a8d8bc7b661f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 52002,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 52002,\n        \"samples\": [\n          \"Describe the character of the protagonist in the given TV show.\",\n          \"Construct a poem that describes the beauty of a sunset.\",\n          \"Describe the effects of exponential growth.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 19188,\n        \"samples\": [\n          \"Step 1: Choose a candidate\\nStep 2: Schedule an interview\\nStep 3: Conduct the interview\\nStep 4: Evaluate the candidate\\nStep 5: Select the candidate\\nStep 6: Notify the candidate\",\n          \"Problem: Traffic congestion in urban areas.\",\n          \"Why is the sky blue?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50842,\n        \"samples\": [\n          \"An appropriate response to this comment could be \\\"Do you want to do something else?\\\".\",\n          \"Five major climate regions are tropical, dry, temperate, continental, and polar.\",\n          \"This dream could be classified as a nightmare. In nightmares, the dreamer is often in a situation that is filled with anxiety, fear, and feelings of helplessness. It can be very difficult to control the situation or find a way to escape. In this dream, the conversations seem to be going wrong and the dreamer cannot find a way to respond correctly. This can increase the sense of helplessness and lead to a nightmare.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df.to_csv('/content/drive/MyDrive/ML/Llama2/data.csv')"
      ],
      "metadata": {
        "id": "lscKe5vIUpDG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df_1k = df[:1000]"
      ],
      "metadata": {
        "id": "5xcy7QqGVFlG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df_1k.to_json('alpaca_data_1k.json', orient='records')"
      ],
      "metadata": {
        "id": "VF31wK-QWTAI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN0pdDHBWaZP",
        "outputId": "e13e2b1d-674f-4b74-f4ed-4ca692c69eca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_1k.json               export_hf_checkpoint.py          pyproject.toml\n",
            "alpaca_data_cleaned_archive.json  export_state_dict_checkpoint.py  README.md\n",
            "alpaca_data_gpt4.json             finetune.py                      requirements.txt\n",
            "alpaca_data.json                  generate.py                      \u001b[0m\u001b[01;34mtemplates\u001b[0m/\n",
            "DATA_LICENSE                      lengths.ipynb                    \u001b[01;34mutils\u001b[0m/\n",
            "docker-compose.yml                LICENSE\n",
            "Dockerfile                        \u001b[01;34mlora-alpaca-1k\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python finetune.py \\\n",
        "    --base_model 'openlm-research/open_llama_3b_v2' \\\n",
        "    --data_path './alpaca_data_1k.json' \\\n",
        "    --output_dir './lora-alpaca-1k' \\\n",
        "    --batch_size 16 \\\n",
        "    --micro_batch_size 16 \\\n",
        "    --num_epochs 4 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --cutoff_len 512 \\\n",
        "    --val_set_size 900 \\\n",
        "    --lora_r 8 \\\n",
        "    --lora_alpha 16 \\\n",
        "    --lora_dropout 0.05 \\\n",
        "    --lora_target_modules '[q_proj,v_proj]' \\\n",
        "    --train_on_inputs \\\n",
        "    --group_by_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChfkofJ2WcOm",
        "outputId": "9e43e6a7-bc06-46ff-d059-7c5c14372198"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Alpaca-LoRA model with params:\n",
            "base_model: openlm-research/open_llama_3b_v2\n",
            "data_path: ./alpaca_data_1k.json\n",
            "output_dir: ./lora-alpaca-1k\n",
            "batch_size: 16\n",
            "micro_batch_size: 16\n",
            "num_epochs: 4\n",
            "learning_rate: 0.0001\n",
            "cutoff_len: 512\n",
            "val_set_size: 900\n",
            "lora_r: 8\n",
            "lora_alpha: 16\n",
            "lora_dropout: 0.05\n",
            "lora_target_modules: ['q_proj', 'v_proj']\n",
            "train_on_inputs: True\n",
            "add_eos_token: False\n",
            "group_by_length: True\n",
            "wandb_project: \n",
            "wandb_run_name: \n",
            "wandb_watch: \n",
            "wandb_log_model: \n",
            "resume_from_checkpoint: False\n",
            "prompt template: alpaca\n",
            "\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:145: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Generating train split: 1000 examples [00:00, 7948.51 examples/s]\n",
            "trainable params: 2,662,400 || all params: 3,429,136,000 || trainable%: 0.07764054852300988\n",
            "Map: 100% 100/100 [00:00<00:00, 174.96 examples/s]\n",
            "Map: 100% 900/900 [00:02<00:00, 383.78 examples/s]\n",
            "2024-03-07 16:33:03.504570: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-07 16:33:03.504733: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-07 16:33:03.631947: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-07 16:33:06.384435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "  0% 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "{'loss': 2.3243, 'grad_norm': 1.0767894983291626, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.43}\n",
            "{'loss': 2.265, 'grad_norm': 1.4774690866470337, 'learning_rate': 1.8e-05, 'epoch': 2.86}\n",
            "{'train_runtime': 254.1906, 'train_samples_per_second': 1.574, 'train_steps_per_second': 0.11, 'train_loss': 2.2709802900041853, 'epoch': 4.0}\n",
            "100% 28/28 [04:14<00:00,  9.08s/it]\n",
            "\n",
            " If there's a warning about missing keys above, please disregard :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK14xlLMWhMO",
        "outputId": "cd24a43a-3c11-4bab-cfec-cd078e38201d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_1k.json               export_hf_checkpoint.py          pyproject.toml\n",
            "alpaca_data_cleaned_archive.json  export_state_dict_checkpoint.py  README.md\n",
            "alpaca_data_gpt4.json             finetune.py                      requirements.txt\n",
            "alpaca_data.json                  generate.py                      \u001b[0m\u001b[01;34mtemplates\u001b[0m/\n",
            "DATA_LICENSE                      lengths.ipynb                    \u001b[01;34mutils\u001b[0m/\n",
            "docker-compose.yml                LICENSE\n",
            "Dockerfile                        \u001b[01;34mlora-alpaca-1k\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gradio==3.50"
      ],
      "metadata": {
        "id": "mfupsJcQeAVx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python generate.py \\\n",
        "#     --base_model 'openlm-research/open_llama_3b_v2' \\\n",
        "#     --lora_weights 'lora-alpaca-1k' \\\n",
        "#     --share_gradio True"
      ],
      "metadata": {
        "id": "7s8CyL1tXBmF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1zbhmdKYgZK",
        "outputId": "b1648803-07de-4c74-f043-e4a6665337d9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpaca_data_1k.json               export_hf_checkpoint.py          pyproject.toml\n",
            "alpaca_data_cleaned_archive.json  export_state_dict_checkpoint.py  README.md\n",
            "alpaca_data_gpt4.json             finetune.py                      requirements.txt\n",
            "alpaca_data.json                  generate.py                      \u001b[0m\u001b[01;34mtemplates\u001b[0m/\n",
            "DATA_LICENSE                      lengths.ipynb                    \u001b[01;34mutils\u001b[0m/\n",
            "docker-compose.yml                LICENSE\n",
            "Dockerfile                        \u001b[01;34mlora-alpaca-1k\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from peft import PeftModel\n",
        "import transformers\n",
        "import gradio as gr\n",
        "\n",
        "assert (\n",
        "    \"LlamaTokenizer\" in transformers._import_structure[\"models.llama\"]\n",
        "), \"LLaMA is now in HuggingFace's main branch.\\nPlease reinstall it: pip uninstall transformers && pip install git+https://github.com/huggingface/transformers.git\"\n",
        "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig"
      ],
      "metadata": {
        "id": "ccw8de51cpCi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = LlamaTokenizer.from_pretrained(\"openlm-research/open_llama_3b_v2\")\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    \"openlm-research/open_llama_3b_v2\",\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42VNIC7lnrjY",
        "outputId": "c9059bde-7aa5-4c25-a21a-b9dca5e1aa3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(\n",
        "    model, \"/content/drive/MyDrive/ML/Llama2/alpaca-lora/lora-alpaca-1k/\", torch_dtype=torch.float16\n",
        ")"
      ],
      "metadata": {
        "id": "Y-b-kQtWoc3s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(instruction, input=None):\n",
        "    if input:\n",
        "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Input:\n",
        "{input}\n",
        "\n",
        "### Response:\"\"\"\n",
        "    else:\n",
        "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{instruction}\n",
        "\n",
        "### Response:\"\"\""
      ],
      "metadata": {
        "id": "ApO2_Z0Mp03G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3MR1snPqvl8",
        "outputId": "e43e51c6-5e24-468c-cb96-0e99c60f28c0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 3200, padding_idx=0)\n",
              "        (layers): ModuleList(\n",
              "          (0-25): 26 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear8bitLt(\n",
              "                (base_layer): Linear8bitLt(in_features=3200, out_features=3200, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3200, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=3200, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (k_proj): Linear8bitLt(in_features=3200, out_features=3200, bias=False)\n",
              "              (v_proj): lora.Linear8bitLt(\n",
              "                (base_layer): Linear8bitLt(in_features=3200, out_features=3200, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=3200, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=3200, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "              )\n",
              "              (o_proj): Linear8bitLt(in_features=3200, out_features=3200, bias=False)\n",
              "              (rotary_emb): LlamaRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear8bitLt(in_features=3200, out_features=8640, bias=False)\n",
              "              (up_proj): Linear8bitLt(in_features=3200, out_features=8640, bias=False)\n",
              "              (down_proj): Linear8bitLt(in_features=8640, out_features=3200, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm()\n",
              "            (post_attention_layernorm): LlamaRMSNorm()\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=3200, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(\n",
        "    instruction,\n",
        "    temperature=0.1,\n",
        "    top_p=0.75,\n",
        "    top_k=40,\n",
        "    num_beams=1,\n",
        "    input=None,\n",
        "    **kwargs,\n",
        "):\n",
        "    prompt = generate_prompt(instruction, input)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"].cuda()\n",
        "\n",
        "    generation_config = GenerationConfig(\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "        **kwargs,\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        generation_output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            generation_config=generation_config,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            max_new_tokens=256,\n",
        "        )\n",
        "    s = generation_output.sequences[0]\n",
        "    output = tokenizer.decode(s)\n",
        "    return output.split(\"### Response:\")[1].strip()"
      ],
      "metadata": {
        "id": "eG_XpEfdqx2N"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(\"What are the three primary colors?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "JpFdYZw5q2U0",
        "outputId": "390ceb1e-419e-4b41-98b5-388409b68005"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Red, Blue, and Green\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n### Task:\\n\\n##'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j9z0z2HGrDnk"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}